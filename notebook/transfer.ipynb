{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import configparser\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "matplotlib.use( 'tkagg' )\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from model import *\n",
    "from lib.preprocessing import *\n",
    "from lib.dataloading import *\n",
    "from lib.loss_functions import *\n",
    "from lib.evaluation import *\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transformer_norm()\n",
    "dataset = SSIDataset(img_file = '../data/ssi.csv', transform= transform['val'], inpaint = True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 1)\n",
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CENet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CENet(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (conv): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 0), output_padding=(1, 0))\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): DecoderBlock(\n",
       "      (conv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For VGG11 UNet    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, padding = 1, output_padding = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBatchRelu(in_channels, middle_channels),\n",
    "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding= padding, output_padding= output_padding),            \n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ConvBatchRelu(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_, out, 3, padding=1)\n",
    "        self.batchnorm = nn.BatchNorm2d(out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['encoder.0.weight', 'encoder.0.bias', 'encoder.1.weight', 'encoder.1.bias', 'encoder.1.running_mean', 'encoder.1.running_var', 'encoder.1.num_batches_tracked', 'encoder.3.weight', 'encoder.3.bias', 'encoder.4.weight', 'encoder.4.bias', 'encoder.4.running_mean', 'encoder.4.running_var', 'encoder.4.num_batches_tracked', 'encoder.7.weight', 'encoder.7.bias', 'encoder.8.weight', 'encoder.8.bias', 'encoder.8.running_mean', 'encoder.8.running_var', 'encoder.8.num_batches_tracked', 'encoder.10.weight', 'encoder.10.bias', 'encoder.11.weight', 'encoder.11.bias', 'encoder.11.running_mean', 'encoder.11.running_var', 'encoder.11.num_batches_tracked', 'encoder.14.weight', 'encoder.14.bias', 'encoder.15.weight', 'encoder.15.bias', 'encoder.15.running_mean', 'encoder.15.running_var', 'encoder.15.num_batches_tracked', 'encoder.17.weight', 'encoder.17.bias', 'encoder.18.weight', 'encoder.18.bias', 'encoder.18.running_mean', 'encoder.18.running_var', 'encoder.18.num_batches_tracked', 'encoder.20.weight', 'encoder.20.bias', 'encoder.21.weight', 'encoder.21.bias', 'encoder.21.running_mean', 'encoder.21.running_var', 'encoder.21.num_batches_tracked', 'encoder.24.weight', 'encoder.24.bias', 'encoder.25.weight', 'encoder.25.bias', 'encoder.25.running_mean', 'encoder.25.running_var', 'encoder.25.num_batches_tracked', 'encoder.27.weight', 'encoder.27.bias', 'encoder.28.weight', 'encoder.28.bias', 'encoder.28.running_mean', 'encoder.28.running_var', 'encoder.28.num_batches_tracked', 'encoder.30.weight', 'encoder.30.bias', 'encoder.31.weight', 'encoder.31.bias', 'encoder.31.running_mean', 'encoder.31.running_var', 'encoder.31.num_batches_tracked', 'encoder.34.weight', 'encoder.34.bias', 'encoder.35.weight', 'encoder.35.bias', 'encoder.35.running_mean', 'encoder.35.running_var', 'encoder.35.num_batches_tracked', 'encoder.37.weight', 'encoder.37.bias', 'encoder.38.weight', 'encoder.38.bias', 'encoder.38.running_mean', 'encoder.38.running_var', 'encoder.38.num_batches_tracked', 'encoder.40.weight', 'encoder.40.bias', 'encoder.41.weight', 'encoder.41.bias', 'encoder.41.running_mean', 'encoder.41.running_var', 'encoder.41.num_batches_tracked', 'decoder.0.conv.weight', 'decoder.0.conv.bias', 'decoder.0.batchnorm.weight', 'decoder.0.batchnorm.bias', 'decoder.0.batchnorm.running_mean', 'decoder.0.batchnorm.running_var', 'decoder.0.batchnorm.num_batches_tracked', 'decoder.1.conv.weight', 'decoder.1.conv.bias', 'decoder.1.batchnorm.weight', 'decoder.1.batchnorm.bias', 'decoder.1.batchnorm.running_mean', 'decoder.1.batchnorm.running_var', 'decoder.1.batchnorm.num_batches_tracked', 'decoder.2.conv.weight', 'decoder.2.conv.bias', 'decoder.2.batchnorm.weight', 'decoder.2.batchnorm.bias', 'decoder.2.batchnorm.running_mean', 'decoder.2.batchnorm.running_var', 'decoder.2.batchnorm.num_batches_tracked', 'decoder.3.conv.weight', 'decoder.3.conv.bias', 'decoder.3.batchnorm.weight', 'decoder.3.batchnorm.bias', 'decoder.3.batchnorm.running_mean', 'decoder.3.batchnorm.running_var', 'decoder.3.batchnorm.num_batches_tracked', 'conv.weight', 'conv.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_dict = torch.load('../results/baseline2/epoch92.pth')\n",
    "pretrained_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_dict = torch.load('../results/baseline2/epoch92.pth')\n",
    "model_dict = vgg.encoder.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "vgg.encoder.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.weight', '0.bias', '1.weight', '1.bias', '1.running_mean', '1.running_var', '1.num_batches_tracked', '3.weight', '3.bias', '4.weight', '4.bias', '4.running_mean', '4.running_var', '4.num_batches_tracked', '7.weight', '7.bias', '8.weight', '8.bias', '8.running_mean', '8.running_var', '8.num_batches_tracked', '10.weight', '10.bias', '11.weight', '11.bias', '11.running_mean', '11.running_var', '11.num_batches_tracked', '14.weight', '14.bias', '15.weight', '15.bias', '15.running_mean', '15.running_var', '15.num_batches_tracked', '17.weight', '17.bias', '18.weight', '18.bias', '18.running_mean', '18.running_var', '18.num_batches_tracked', '20.weight', '20.bias', '21.weight', '21.bias', '21.running_mean', '21.running_var', '21.num_batches_tracked', '24.weight', '24.bias', '25.weight', '25.bias', '25.running_mean', '25.running_var', '25.num_batches_tracked', '27.weight', '27.bias', '28.weight', '28.bias', '28.running_mean', '28.running_var', '28.num_batches_tracked', '30.weight', '30.bias', '31.weight', '31.bias', '31.running_mean', '31.running_var', '31.num_batches_tracked', '34.weight', '34.bias', '35.weight', '35.bias', '35.running_mean', '35.running_var', '35.num_batches_tracked', '37.weight', '37.bias', '38.weight', '38.bias', '38.running_mean', '38.running_var', '38.num_batches_tracked', '40.weight', '40.bias', '41.weight', '41.bias', '41.running_mean', '41.running_var', '41.num_batches_tracked'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = '../results/baseline2/epoch92.pth'\n",
    "pretrained_dict = torch.load(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0350, -0.0227,  0.0022],\n",
       "         [ 0.0654,  0.0476, -0.0699],\n",
       "         [ 0.0331, -0.1387, -0.0050]],\n",
       "\n",
       "        [[-0.1026,  0.0149,  0.0538],\n",
       "         [ 0.0293, -0.0288,  0.0078],\n",
       "         [-0.0041, -0.1956,  0.1362]],\n",
       "\n",
       "        [[ 0.0335,  0.0263, -0.0362],\n",
       "         [-0.0766, -0.0320, -0.0965],\n",
       "         [ 0.1025, -0.1313, -0.0382]]], device='cuda:0')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_dict['encoder.0.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16UNet(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, self_trained = False, freeze = False, is_deconv=False):\n",
    "        \"\"\"\n",
    "        :param num_classes:\n",
    "        :param num_filters:\n",
    "        :param pretrained:\n",
    "            False - no pre-trained network used\n",
    "            True - encoder pre-trained with VGG16\n",
    "        :is_deconv:\n",
    "            False: bilinear interpolation is used in decoder\n",
    "            True: deconvolution is used in decoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.encoder = models.vgg16_bn(pretrained=pretrained).features\n",
    "                \n",
    "        if self_trained:\n",
    "            weight_path = '../results/baseline2/epoch92.pth'\n",
    "            print(f\"Load weights from {weight_path}\")\n",
    "            pretrained_dict = torch.load(weight_path)            \n",
    "            model_dict = self.state_dict()            \n",
    "            # 1. filter out unnecessary keys\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "            # 2. overwrite entries in the existing state dict\n",
    "            model_dict.update(pretrained_dict)             \n",
    "            \n",
    "            # 3. load the new state dict0            \n",
    "            self.load_state_dict(model_dict)                    \n",
    "        \n",
    "        if freeze:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.require_grad = False\n",
    "                \n",
    "        self.relu = nn.ReLU(inplace=True)                \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "                \n",
    "        self.conv1 = nn.Sequential(self.encoder[0],\n",
    "                                   self.encoder[1],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[3],\n",
    "                                   self.encoder[4],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv2 = nn.Sequential(self.encoder[7],\n",
    "                                   self.encoder[8],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[10],\n",
    "                                   self.encoder[11],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv3 = nn.Sequential(self.encoder[14],\n",
    "                                   self.encoder[15],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[17],\n",
    "                                   self.encoder[18],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[20],\n",
    "                                   self.encoder[21],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv4 = nn.Sequential(self.encoder[24],\n",
    "                                   self.encoder[25],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[27],\n",
    "                                   self.encoder[28],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[30],\n",
    "                                   self.encoder[31],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv5 = nn.Sequential(self.encoder[34],\n",
    "                                   self.encoder[35],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[37],\n",
    "                                   self.encoder[38],\n",
    "                                   self.relu,\n",
    "                                   self.encoder[40],\n",
    "                                   self.encoder[41],\n",
    "                                   self.relu)\n",
    "    \n",
    "        self.center = DecoderBlock(512, num_filters * 8 * 2, num_filters * 8, padding = (1,0), output_padding = (1,0))\n",
    "\n",
    "        self.dec5 = DecoderBlock(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8)\n",
    "        self.dec4 = DecoderBlock(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8)\n",
    "        self.dec3 = DecoderBlock(256 + num_filters * 8, num_filters * 4 * 2, num_filters * 2)\n",
    "        self.dec2 = DecoderBlock(128 + num_filters * 2, num_filters * 2 * 2, num_filters)\n",
    "        self.dec1 = ConvBatchRelu(64 + num_filters, num_filters)\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(self.pool(conv1))\n",
    "        conv3 = self.conv3(self.pool(conv2))\n",
    "        conv4 = self.conv4(self.pool(conv3))\n",
    "        conv5 = self.conv5(self.pool(conv4))\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "\n",
    "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
    "\n",
    "        if self.num_classes > 1:\n",
    "            x_out = F.log_softmax(self.final(dec1), dim=1)\n",
    "        else:\n",
    "            x_out = self.final(dec1)\n",
    "\n",
    "        return F.sigmoid(x_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights from ../results/baseline2/epoch92.pth\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16UNet(num_classes=2, pretrained=False, self_trained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0080, -0.0645,  0.0364],\n",
       "         [ 0.0237,  0.0199,  0.0402],\n",
       "         [-0.0632,  0.0091,  0.0989]],\n",
       "\n",
       "        [[ 0.0625, -0.0922, -0.0725],\n",
       "         [ 0.0359,  0.0855, -0.0374],\n",
       "         [-0.0504,  0.0304,  0.0501]],\n",
       "\n",
       "        [[ 0.0345,  0.0371, -0.0076],\n",
       "         [ 0.0128,  0.0458, -0.0714],\n",
       "         [ 0.0350, -0.0945, -0.0777]]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vgg.conv1[0].weight.data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0350, -0.0227,  0.0022],\n",
       "         [ 0.0654,  0.0476, -0.0699],\n",
       "         [ 0.0331, -0.1387, -0.0050]],\n",
       "\n",
       "        [[-0.1026,  0.0149,  0.0538],\n",
       "         [ 0.0293, -0.0288,  0.0078],\n",
       "         [-0.0041, -0.1956,  0.1362]],\n",
       "\n",
       "        [[ 0.0335,  0.0263, -0.0362],\n",
       "         [-0.0766, -0.0320, -0.0965],\n",
       "         [ 0.1025, -0.1313, -0.0382]]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.encoder.state_dict()['0.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/anaconda3/envs/curt/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "out = vgg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 256, 400])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
